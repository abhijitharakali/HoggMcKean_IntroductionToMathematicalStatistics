{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c05fc26",
   "metadata": {},
   "source": [
    "Tomoki has solutions, and solutions manual also has some solutions. I have just added some of my own thoughts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e41d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import pylab as py\n",
    "import scipy.linalg as la\n",
    "import statistics\n",
    "import scipy.stats as stats\n",
    "import scipy\n",
    "\n",
    "from math import gamma as tma\n",
    "import itertools\n",
    "from scipy.stats import laplace\n",
    "from scipy.stats import logistic\n",
    "from scipy.stats import cauchy\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import weibull_min as weibull\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import gamma\n",
    "from scipy.stats import beta\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal as mnorm\n",
    "from scipy.stats import t as studt\n",
    "from scipy.stats import f as fdist\n",
    "from scipy.stats import chisquare as chisq\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import gaussian_kde as gkde\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import math\n",
    "import sympy as sym\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.cbook import boxplot_stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9ef519",
   "metadata": {},
   "source": [
    "#### Exercise 7.4.3\n",
    "\n",
    "Let $X_1, X_2, \\cdots, X_n$ represent a random sample from the discrete distribution having the pmf\n",
    "$f (x; \\theta) =  \\theta^x(1−\\theta)^{1−x}$, $x=0,1, 0<\\theta<1$, and $f (x; \\theta) = 0$ elsewhere.\n",
    "Show that $Y_1 = \\sum_1^n X_i$ is a complete sufficient statistic for $\\theta$. Find the unique function of $Y_1$ that is the MVUE of $\\theta$.\n",
    "\n",
    "$Hint$: Display $E[u(Y_1)] = 0$, show that the constant term $u(0)$ is equal to zero, divide both members of the equation by $\\theta \\neq 0$, and repeat the argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2634f3ea",
   "metadata": {},
   "source": [
    "#### Solution:\n",
    "\n",
    "Sum of Bernoulli iid random variables follows $b(n,\\theta)$. So $E(u(Y_1)) = 0$ amounts to $$\\sum_0^n {n\\choose k}\\theta^k(1-\\theta)^{n-k}u(k) = 0.$$ Now $\\theta \\in (0,1) \\implies 1-\\theta > 0$. So as shown in solutions manual (solution to exercise 7.4.8 (b)), we can divide throughout by $(1-\\theta)^n$, and define $\\gamma = \\theta/(1-\\theta)$. With $\\theta \\in (0,1)$, we have $\\gamma \\in (0,\\infty)$.\n",
    "\n",
    "Then we will have a polynomial equation in $\\gamma$, namely $$\\sum_0^n {n\\choose k}\\gamma^ku(k) = 0,$$ which holds for any $\\gamma \\in (0,\\infty)$. This implies $u(k) = 0$, $\\forall k \\in \\{0,1,2,3\\cdots,n\\}$ and hence $Y_1$ is a complete statistic for $\\theta$. Since $E(Y_1) = n\\theta$, $Y_1/n$ is the MVUE for $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc0b7b1",
   "metadata": {},
   "source": [
    "#### Exercise 7.4.5. \n",
    "\n",
    "Show that the first order statistic $Y_1$ of a random sample of size $n$ from the distribution having pdf $f(x;\\theta) = e^{−(x−\\theta)}$, $\\theta < x < \\infty$, $−\\infty < \\theta < \\infty$, zero elsewhere, is a complete sufficient statistic for $\\theta$. Find the unique function of this statistic which is the MVUE of $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a7b5fa",
   "metadata": {},
   "source": [
    "#### Solution:\n",
    "\n",
    "Basically $f_{Y_1}(y) = ne^{-n(y-\\theta)}I_{(\\theta,\\infty)}$ so as usual, $E(u(Y_1)) = 0$ amounts to $\\int_{\\theta}^{\\infty}ne^{-n(y-\\theta)}u(y)dy = 0$ which upon differenciation w.r.t $\\theta$ gives $u(\\theta) = 0$ $-\\infty < \\theta < \\infty$. Hence $Y_1$ is a complete statistic for $\\theta$.\n",
    "\n",
    "Since $E(Y_1) = \\theta+1/n$, the MVUE for $\\theta$ is $Y_1-1/n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2624411c",
   "metadata": {},
   "source": [
    "#### Exercise 7.4.9\n",
    "\n",
    "For part (c), see\n",
    "\n",
    "https://math.stackexchange.com/a/3627402/145325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f300c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
